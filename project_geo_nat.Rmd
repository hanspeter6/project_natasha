---
title: "Soil Characteristics and Burn"
author: "Hans-Peter Bakker  for Natasha Moore"
date: "6/1/2018"
output:
  word_document: default
  pdf_document: default
  html_document: default
bibliography: natasha.bib
---
---
nocite: |
        @rpart, @rpart.plot, @dplyr, @FactoMineR, @factoextra, @caret, @brglm, @corrplot, @mice, @glmnet, @RStudio, @bestglm, @VIM, @faraway
...


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, error = FALSE)
```

```{r}
# libraries:
library(dplyr)
library(FactoMineR)
library(factoextra)
library(rpart)
library(rpart.plot)
library(caret)
# library(logistf)
library(brglm)
library(corrplot)
library(mice)
library(bestglm)
library(mice)
library(VIM)
library(faraway)
```

```{r}
# read .csv file:
geo_data <- read.table("trial2.csv",
                       header = TRUE, sep = ";")
```
##Data Cleaning and Initial Exploration

After first abbreviating or shortening some of variable names and some of the category labels, the provided Excel spreadsheet was read in as a .csv file.

The variables *site*, *type* and *burn* were converted to factor variables.

Summaries of the variables are shown below and reflect a few missing values for *hsv* and for *hp*. The analysis will first proceed with only the complete cases. The impact of the missing data was considered later.

```{r}
#change site, type, burn to factor variables
geo_data$site <- factor(geo_data$site)
geo_data$type <- factor(geo_data$type)
geo_data$burn <- factor(geo_data$burn, labels = c("No Burn", "Burn"))

summary(geo_data)
```

```{r}
# numeric dataset
geo_data_nums <- data.frame(scale(geo_data[,c('elevation',
                                              'slope',
                                              'hsv', # 3 NA's
                                              'hp',
                                              'moisture',
                                              'ph',
                                              'loss_ig',
                                              'sand',
                                              # 'silt', # due to singularity
                                              'clay')]))

```

Given the linear dependence between between *silt*, *clay* and *sand* (they add up to 100%), *silt* was dropped from the dataset.

### Correlation Matrix

A plot indicating the correlations between the numeric variables is shown below (and a .jpeg file for publication was generated).

```{r}
# consider correlations
cor_mat <- cor(geo_data_nums, use = 'pairwise.complete.obs')
corrplot(cor_mat, method = 'pie', tl.col = "black")
jpeg("corrplot1_geo.jpeg")
corrplot(cor_mat, method = 'pie', tl.col = "black")
dev.off()
```

The strong correlation between *moisture* and *loss_ig* would suggest that only one of these is required. The relatively strong negative correlation between *sand* and *clay* can also be expected due to the fact that a high percentage of the one automatically implies a low percentage of the other.

The generally high levels of correlation would suggest that dimension reduction may be worth considering, although it would  be accompanied by more difficult interpretations.

### Principal Components Analysis

To examine the latent dimensionality of the numerical data, principal components analysis was done on the standardised numeric variables. The scree plot (with *elbows* at 3 and 6) in conjunction with the summary output below suggests the selection of four components, reflecting a cumulative ~83% of the variance. (a .jpeg file of the screeplot is also generated)

```{r}
# to explore dimensionality of numerical variables for now only complete cases
pca_geo <- princomp(geo_data_nums[complete.cases(geo_data_nums),])
screeplot(pca_geo, type = "lines", main = "Scree Plot of Principal Components", npcs = 8)
abline(v = 4, lty = 2)
# for printing:
jpeg("pca_screeplot.jpeg")
screeplot(pca_geo, type = "lines", main = "Scree Plot of Principal Components", npcs = 8)
abline(v = 4, lty = 2)
dev.off()

summary(pca_geo)
```

The vector plots and the loadings below give some idea of the contributions of variables to the four dimensions. These could be used to interpret the meaning of the components/factors.

Although this approach may be interesting as a point of discussion on how the variables relate to each other, taking this approach further would more likely lead to greater difficulties in the interpretation of outcomes and effects. If required however, this approach of working with latent constructs can be pursued.

```{r}
# using factomineR
pca_geo_factoMineR <- PCA(geo_data_nums[complete.cases(geo_data_nums),], ncp = 4, graph = FALSE)

sweep(pca_geo_factoMineR$var$coord,2,sqrt(pca_geo_factoMineR$eig[1:ncol(pca_geo_factoMineR$var$coord),1]),FUN="/")

fviz_pca_var(pca_geo_factoMineR,
             axes = c(1,2),
             col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             title = "Dimensions 1 & 2",
             repel = TRUE # Avoid text overlapping
)

jpeg("contributions_pca_1n2.jpeg")
fviz_pca_var(pca_geo_factoMineR,
             axes = c(1,2),
             col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             title = "Dimensions 1 & 2",
             repel = TRUE # Avoid text overlapping
)
dev.off()

fviz_pca_var(pca_geo_factoMineR,
             axes = c(3,4),
             col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             title = "Dimensions 3 & 4",
             repel = TRUE # Avoid text overlapping
)

jpeg("contributions_pca_3n4.jpeg")
fviz_pca_var(pca_geo_factoMineR,
             axes = c(3,4),
             col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             title = "Dimensions 3 & 4",
             repel = TRUE # Avoid text overlapping
)
dev.off()

```
## Partition Tree

To offer some initial exploration of the link between the variables and the outcome (*Burn* or *No Burn*), a simple partition exercise (or *tree*) was considered with all the variables - numeric and categorical - as response variables. Only the adjusted (reduced levels) categorical variables were used. 

Two plots showing the first four levels are shown below. (and also added as a further .jpeg file for use in publication). In the second plot, the variable *colour* was removed.

```{r}
# consider classification tree for explanatory reasons:
tree_geo1 <- rpart(burn ~ 
                          area2 +
                          geology2 +
                          aspect2 +
                          veg +
                          elevation +
                          slope +
                          hsv +
                          hp +
                          moisture +
                          ph +
                          loss_ig +
                          colour +
                          sand +
                          silt +
                          clay
                          ,
                  data = geo_data)

tree_geo2 <- rpart(burn ~ 
                          area2 +
                          geology2 +
                          aspect2 +
                          veg +
                          elevation +
                          slope +
                          hsv +
                          hp +
                          moisture +
                          ph +
                          loss_ig +
                          # colour +
                          sand +
                          silt +
                          clay
                          ,
                  data = geo_data)
```

```{r}

# all variables
rpart.plot(tree_geo1, type = 4, extra = 1, cex = 0.8, main = "Burn Partition: All Variables")

jpeg("partition_tree1.jpeg")
rpart.plot(tree_geo1, type = 4, extra = 1, cex = 0.8, main = "Burn Partition: All Variables")
dev.off()

# minus 'colour'
rpart.plot(tree_geo2, type = 4, extra = 1, cex = 0.8, main = "Burn Partition: Minus *colour*")

jpeg("partition_tree2.jpeg")
rpart.plot(tree_geo2, type = 4, extra = 1, cex = 0.8, main = "Burn Partition: Minus *colour*")
dev.off()

```

The predictive power of the second partitioning model (without *colour*), which showed higher levels of accuracy than the full set, using the existing data as predictors, suggests relatively high levels of accuracy - as can be seen in the confusion matrix and relevant statistics shown below. If the purpose of this project was prediction, this line of investigation could be pursued into considering random forests and other methods.

```{r}
# consider prediction power of single tree:
pred_class <- predict(tree_geo2, type = "class")
confusionMatrix(data = pred_class, reference = geo_data$burn, positive = "Burn")
```

## Logistic Regression 

Given the binomial nature of the outcome variable, logistic regression was considered to quantify the relative importance of predictor variables on the class of outcome.

Initial attempts were thwarted due to the fact that the data appeared to be perfectly separable. This meant that the standard estimating methods (Fisher's Scoring) could not be applied. An examination of the data indicated that various combinations of the variables were responsible for the separation and as a result it was not possible to reconstitute or reconsider one or two of the variables only. An alternative, *bias reduction*, method proposed by Firth (1993) and cited in @brglm was adopted. Although this method may offer only second-order unbiased results, the estimates are finite and compare well with more established estimating procedures.

Given the number of variables it was possible to run iterations of all possible combinations of explanatory variables to identify the top five subset selections by their Bayesian Information Criterion (BIC).

```{r cache = TRUE}
xy_frame <- geo_data %>%
        select( area2,
                geology2,
                aspect2,
                veg,
                elevation,
                slope,
                hsv ,
                hp,
                moisture,
                ph,
                loss_ig,
                colour,
                sand,
                clay,
                y = burn)
best_set_bic <- bestglm(xy_frame, family = binomial, IC = "BIC", method = "exhaustive")
# best_set_bicq <- bestglm(xy_frame, family = binomial, IC = "BICq", q = 0.25, method = "exhaustive")
```


```{r}
best_set_bic$BestModels
#summary(best_set_bic$BestModel) #can use this to build model using brglm()
```

The first, "best" model, which includes both *aspect* and *veg*, but not *colour* was be used in the modelling below.

The list of variables that were included in the estimation of the first model will therefore be:

* *aspect*
* *veg*
* *elevation*
* *hsv*
* *hp*
* *ph*
* *loss_ig*
* *sand*

```{r}
model_geo <- brglm(burn ~
                         aspect2 +
                         veg +
                         elevation +
                         hsv +
                         hp +
                         ph +
                         loss_ig +
                         sand,
                 data = geo_data,
                 family = "binomial")

```

To consider the model fit, its *deviance*, which in logistic regression can be considered to exhibit a Chi-Squared ($\chi^2$) distribution, and the model's degrees of freedom were used to test for significance. A p-value of close to one, and therefore considerably larger than an 0.05 cut-off level, indicated an acceptable fit (@farawayExt).

Additionally, the squared correlation between model predicted and observed outcomes was considered and, given a value of `r round(cor(ifelse(predict(model_geo, type = "response") > 0.5, 1, 0), ifelse(geo_data$burn[-c(35,64,79)] == "Burn", 1, 0))^2, 4) `, confirms a reasonable result.

A measure of fit which is analogous with $R^2$ - a popular measure of fit for normal linear models as a indication of the proportion of variance explained by the model - as described by Nagelkerke (1991) and cited in @farawayExt (p41) was used to calculate a proportion of variance explained by the model of `r round((1-exp((model_geo$deviance - model_geo$null.deviance)/82))/(1-exp(-model_geo$null.deviance/82)),3) `, which is good.

Furthermore, a *halfnorm* plot of the residuals, shown below, provides further evidence of a fit without overdispersion of residuals @farawayExt.

```{r}
halfnorm(residuals(model_geo))
```

Finally, as with the partition tree above, a confusion matrix, shown below, was drawn from the observed and predicted values,indicating a model with strong predictive power.

```{r}
#  `r round(pchisq(deviance(model_geo), df.residual(model_geo), lower = FALSE))`
# # consider observed vs fitted values: and compute the pearson correlation 'r' . Squaring it gives good idea..
preds <- predict(model_geo, type = "response")
# preds_num <- ifelse(predict(model_geo, type = "response") > 0.5, 1, 0)
# obs_num <- ifelse(geo_data$burn[-c(35,64,79)] == "Burn", 1, 0)
# round(cor(ifelse(predict(model_geo, type = "response") > 0.5, 1, 0), ifelse(geo_data$burn[-c(35,64,79)] == "Burn", 1, 0))^2, 4)

# confusion matrix
preds_cat <- ifelse(preds > 0.5, "No Burn", "Burn")
confusionMatrix(preds_cat, geo_data$burn[-c(35,64,79)], positive = "Burn")

```

The summary output for this model to be used for interpreting coefficients of independent variables is printed below: 

```{r}
summary(model_geo)
```

## Treatment of Missing Data

Using Predictive Mean Matching multiple (50) imputed datasets were pooled and the same model was fitted on the pooled data. See @pmm.

```{r cache = TRUE}
# generating imputed values
imputed <- mice(geo_data, print = FALSE, m = 50)

# method = Predictive Mean Matching : check out: #https://statisticalhorizons.com/predictive-mean-matching

# marginplot(geo_data[,c('hsv', 'hp')], col = mdc(1:2))
```

Plots indicating distributions of imputed values are shown below. The idea is to ensure that the imputed values (in red) are distributed similarly to the observed values (in blue) for the two variables.

```{r}
stripplot(imputed, hsv + hp ~ .imp, pch = 20, cex = 1.3)
```

The same model as was developed above was fitted using the pooled datasets. The summary output is shown below. The coefficient estimates are not substantively different from the model in which the sample with missing values were excluded. *fmi* indicates the fraction of missing data and *lambda* is a measure of the proportion of total variance attributed to the missing data.

Given the marginal difference of using the pooled imputed model and the model that discounts the missing values, it is suggested that the samples with missing values simply be excluded and that the research proceeds with the logistic model described above.

```{r}
fit <- with(imputed, brglm(burn ~
                                         aspect2 +
                                         veg +
                                         elevation +
                                         hsv +
                                         hp +
                                         ph +
                                         loss_ig +
                                         sand))
pooled <- pool(fit)
round(summary(pooled),4)
```

#### Please note:
*The interpretation of the estimated coefficients needs to consider the logistic nature of these estimating procedures. Please don't hesitate to ask for help*

Below are some guidelines to help with the interpretation. The first formula links the 12 coefficient estimates with observed variable values.
$$log(odds) = \beta_0 + \beta_1aspect2North + \beta_2aspect2South + ... + \beta_9ph + \beta_{10}loss_ig + \beta_{11}sand$$
where, $$odds = \frac{(Probability(Burn)}{Probability(No Burn)}$$
which, when transformed can give you:
$$P(Burn) = \frac{odds}{(1 + odds)}$$
# References
